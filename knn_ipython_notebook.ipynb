{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-Nearest Neighbor Classification Algorithm \n",
    "\n",
    "import numpy as np\n",
    "import math as math\n",
    "import random\n",
    "from numpy import linalg as la\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "# Loads the corresponding file into the association matrix\n",
    "def load_dataset(file_name):\n",
    "    records = []\n",
    "    with open(file_name,'r') as f:\n",
    "        for vals in f:\n",
    "            splitter = vals.split()\n",
    "            temp = []\n",
    "            for attributes in splitter:\n",
    "                try:\n",
    "                    x = float(attributes)\n",
    "                    temp.append(x)\n",
    "                except ValueError:\n",
    "                    temp.append(attributes)\n",
    "            records.append(temp)\n",
    "    print(\"Total Number of Records in \" + str(file_name) + \" Dataset : \" + str(len(records)))\n",
    "    return records\n",
    "\n",
    "    \n",
    "def form_training_testing_data(records, k_fold, ind):\n",
    "    l = len(records)\n",
    "    index = l / k_fold\n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    if(ind != 1 and ind != k_fold):\n",
    "        start = int (index * (ind-1))\n",
    "        end = int (index * ind)\n",
    "    elif(ind == 1):\n",
    "        start = 0\n",
    "        end = int (index * ind)\n",
    "    elif(ind == k_fold):\n",
    "        start = int (index * (ind-1))\n",
    "        end = l-1\n",
    "    for i, j in enumerate(records):\n",
    "        if(ind != 1 and ind != k_fold):\n",
    "            if(i < start or i >= end):\n",
    "                train_data.append(j)\n",
    "            else:\n",
    "                test_data.append(j)\n",
    "        elif(ind == 1):\n",
    "            if(i >= start and i < end):\n",
    "                test_data.append(j)\n",
    "            else:\n",
    "                train_data.append(j)\n",
    "        elif(ind == k_fold):\n",
    "            if(i >= start and i <= end):\n",
    "                test_data.append(j)\n",
    "            else:\n",
    "                train_data.append(j)\n",
    "    print(\"Number of Records in Training Dataset : \" + str(len(train_data)))\n",
    "    print(\"Number of Records in Testing Dataset : \" + str(len(test_data)))\n",
    "    return train_data, test_data\n",
    "\n",
    "def calculate_statistics(test_data, predicted_labels):\n",
    "    length = len(test_data)\n",
    "    tn = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for i in range(length):\n",
    "        if(predicted_labels[i] == test_data[i][-1]):\n",
    "            if(predicted_labels[i] == 0):\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if(predicted_labels[i] == 0 and test_data[i][-1] == 1):\n",
    "                fn = fn + 1\n",
    "            elif(predicted_labels[i] == 1 and test_data[i][-1] == 0):\n",
    "                fp = fp + 1\n",
    "    try:\n",
    "        accuracy = 100.0 * ((tp + tn) / float(tn + tp + fn + fp))\n",
    "    except ZeroDivisionError:\n",
    "        accuracy = 100.0 * (tp + tn)\n",
    "    try:\n",
    "        precision = tp / float(tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = tp\n",
    "    try:\n",
    "        recall = tp / float(tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = tp\n",
    "    try:\n",
    "        f_measure = (2 * tp) / float((2 * tp) + fn + fp)\n",
    "    except ZeroDivisionError:\n",
    "        f_measure = (2 * tp)\n",
    "    return accuracy, precision, recall, f_measure\n",
    "        \n",
    "\n",
    "def count_votes(nearest_neighbors):\n",
    "    length = len(nearest_neighbors)\n",
    "    predicted_label = {}\n",
    "    for i in range(length):\n",
    "        label = nearest_neighbors[i][-1]\n",
    "        if label in predicted_label:\n",
    "            predicted_label[label] = predicted_label[label] + 1\n",
    "        else:\n",
    "            predicted_label[label] = 1\n",
    "    final_predicted_label = sorted(predicted_label.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return final_predicted_label[0][0]\n",
    "\n",
    "def calculate_euclidean_distance(train_data, test_data, length):\n",
    "    euclidean_distance = 0\n",
    "    counter = 0\n",
    "    for (trn, tst) in itertools.zip_longest(train_data, test_data): \n",
    "        if(counter < length):\n",
    "            try:\n",
    "                x = float(trn)\n",
    "                y = float(tst)\n",
    "                euclidean_distance = euclidean_distance + math.pow(trn - tst, 2)\n",
    "            except ValueError:\n",
    "                if(trn == tst):\n",
    "                    euclidean_distance = euclidean_distance + 0\n",
    "                else:\n",
    "                    euclidean_distance = euclidean_distance + 1\n",
    "        counter = counter + 1\n",
    "    dist = math.sqrt(euclidean_distance)\n",
    "    return dist\n",
    "    \n",
    "    \n",
    "def find_nearest_neighbors(train_data, test_data, k):\n",
    "    distance = []\n",
    "    for pos, val in enumerate(train_data):\n",
    "        length = len(val)-1\n",
    "        dist = calculate_euclidean_distance(val,test_data, length)\n",
    "        distance.append((val,dist))\n",
    "    distance.sort(key=operator.itemgetter(1))\n",
    "    nearest_neighbors = []\n",
    "    for i in range(k):\n",
    "        nearest_neighbors.append(distance[i][0])\n",
    "    return nearest_neighbors\n",
    "    \n",
    "file_name = \"project3_dataset1.txt\"\n",
    "#file_name = \"project3_dataset2.txt\"\n",
    "\n",
    "k = 10\n",
    "k_fold_validation = 10\n",
    "\n",
    "# Load the corresponding dataset to fetch records.\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_measure = 0\n",
    "records = load_dataset(file_name)\n",
    "for i in range(k_fold_validation):\n",
    "    print(\"\\nIteration \" + str(i+1))\n",
    "    train_data, test_data = form_training_testing_data(records,k_fold_validation, i+1)\n",
    "    predicted_labels = []\n",
    "    for pos, val in enumerate(test_data):\n",
    "        nearest_neighbors = find_nearest_neighbors(train_data, val, k)\n",
    "        label = count_votes(nearest_neighbors)\n",
    "        predicted_labels.append(label)\n",
    "    acc, prec, rec, f = calculate_statistics(test_data, predicted_labels)\n",
    "    accuracy = accuracy + acc\n",
    "    precision = precision + prec\n",
    "    recall = recall + rec\n",
    "    f_measure = f_measure + f\n",
    "    print(\"*** Iteration \" + str(i+1) + \" Statistics *** \")\n",
    "    print(\"Accuracy : \" + str(acc))\n",
    "    print(\"Precision : \" + str(prec))\n",
    "    print(\"Recall : \" + str(rec))\n",
    "    print(\"F-1 Measure : \" + str(f))\n",
    "    \n",
    "accuracy = accuracy / float (k_fold_validation)\n",
    "precision = precision / float (k_fold_validation)\n",
    "recall = recall / float (k_fold_validation)\n",
    "f_measure = f_measure / float (k_fold_validation)\n",
    "print(\"\\n\\n***** KNN Classification Statistics Obtained Using \" + str(k_fold_validation)+ \"-Fold Cross Validation ***** \")\n",
    "print(\"Accuracy : \" + str(accuracy))\n",
    "print(\"Precision : \" + str(precision))\n",
    "print(\"Recall : \" + str(recall))\n",
    "print(\"F-1 Measure : \" + str(f_measure))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
