{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Classification Algorithm \n",
    "\n",
    "import numpy as np\n",
    "import math as math\n",
    "import random\n",
    "from numpy import linalg as la\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "# Loads the corresponding file into the association matrix\n",
    "def load_dataset(file_name):\n",
    "    records = []\n",
    "    with open(file_name,'r') as f:\n",
    "        for vals in f:\n",
    "            splitter = vals.split()\n",
    "            temp = []\n",
    "            for attributes in splitter:\n",
    "                try:\n",
    "                    x = float(attributes)\n",
    "                    temp.append(x)\n",
    "                except ValueError:\n",
    "                    temp.append(attributes)\n",
    "            records.append(temp)\n",
    "    print(\"Total Number of Records in \" + str(file_name) + \" Dataset : \" + str(len(records)))\n",
    "    return records\n",
    "\n",
    "    \n",
    "def form_training_testing_data(records, k_fold, ind):\n",
    "    l = len(records)\n",
    "    index = l / k_fold\n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    if(ind != 1 and ind != k_fold):\n",
    "        start = int (index * (ind-1))\n",
    "        end = int (index * ind)\n",
    "    elif(ind == 1):\n",
    "        start = 0\n",
    "        end = int (index * ind)\n",
    "    elif(ind == k_fold):\n",
    "        start = int (index * (ind-1))\n",
    "        end = l-1\n",
    "    for i, j in enumerate(records):\n",
    "        if(ind != 1 and ind != k_fold):\n",
    "            if(i < start or i >= end):\n",
    "                train_data.append(j)\n",
    "            else:\n",
    "                test_data.append(j)\n",
    "        elif(ind == 1):\n",
    "            if(i >= start and i < end):\n",
    "                test_data.append(j)\n",
    "            else:\n",
    "                train_data.append(j)\n",
    "        elif(ind == k_fold):\n",
    "            if(i >= start and i <= end):\n",
    "                test_data.append(j)\n",
    "            else:\n",
    "                train_data.append(j)\n",
    "    print(\"Number of Records in Training Dataset : \" + str(len(train_data)))\n",
    "    print(\"Number of Records in Testing Dataset : \" + str(len(test_data)))\n",
    "    return train_data, test_data\n",
    "\n",
    "def calculate_class_prior(train_data):\n",
    "    length = len(train_data)\n",
    "    class_prior = {}\n",
    "    for i in range(length):\n",
    "        label = train_data[i][-1]\n",
    "        if label in class_prior:\n",
    "            class_prior[label] = class_prior[label] + 1\n",
    "        else:\n",
    "            class_prior[label] = 1\n",
    "    for key in class_prior.keys():\n",
    "        val = class_prior.get(key)\n",
    "        class_prior[key] = val / float(length)\n",
    "        print(\"Class-\" + str(key) + \" Prior Probablity : \" + str(class_prior[key]))\n",
    "    return class_prior\n",
    "\n",
    "def calculate_descriptor_posterior(test_data, train_data, label):\n",
    "    denominator = 0 \n",
    "    descriptor_posterior = 1\n",
    "    hmap = {}       \n",
    "    for pos, val in enumerate(train_data):\n",
    "        if(val[-1] == label):\n",
    "            denominator = denominator + 1\n",
    "    hmap = map_descriptor_posterior_probablities(hmap, test_data, train_data, label)\n",
    "    for key in hmap.keys():\n",
    "        val = hmap.get(key)\n",
    "        descriptor_posterior = (descriptor_posterior / float(denominator)) * val\n",
    "    return descriptor_posterior\n",
    "        \n",
    "\n",
    "def map_descriptor_posterior_probablities(hmap, test_data, train_data, label):\n",
    "    counter = 0\n",
    "    length = len(test_data)\n",
    "    for pos, val in enumerate(test_data):\n",
    "        if(pos < length - 1):\n",
    "            for p, q in enumerate(train_data):\n",
    "                for i in range(len(q)):\n",
    "                    if(i < length - 1):\n",
    "                        if((i == pos) and (q[i] == val) and (q[-1] == label)):\n",
    "                            if i in hmap:\n",
    "                                hmap[i] = hmap[i] + 1\n",
    "                            else:\n",
    "                                hmap[i] = 1\n",
    "    return hmap                                    \n",
    "\n",
    "def calculate_mean_variance(train_data, position):\n",
    "    hmap = {}\n",
    "    \"\"\"for pos, val in enumerate(train_data):\n",
    "        l = len(val)\n",
    "        for i, j in enumerate(val):\n",
    "            if(i < l - 1):\n",
    "                if(val[-1] == label):\n",
    "                    if i in hmap:\n",
    "                        y = hmap.get(i)\n",
    "                        y.append(j)\n",
    "                    else:\n",
    "                        x = []\n",
    "                        x.append(j)\n",
    "                        hmap[i] = x \"\"\"\n",
    "\n",
    "    for pos, val in enumerate(train_data):\n",
    "        label = val[-1]\n",
    "        attribute = val[position]\n",
    "        if label in hmap:\n",
    "            tmp = hmap.get(label)\n",
    "            tmp.append(attribute)\n",
    "            hmap[label] = tmp\n",
    "        else:\n",
    "            temp = []\n",
    "            temp.append(attribute)\n",
    "            hmap[label] = temp\n",
    "            \n",
    "    statistics = {}\n",
    "    for key in hmap.keys():\n",
    "        x = hmap.get(key)\n",
    "        mean = np.mean(x)\n",
    "        variance = np.var(x)\n",
    "        temp = []\n",
    "        temp.append(mean)\n",
    "        temp.append(variance)\n",
    "        statistics[key] = temp\n",
    "    return statistics\n",
    "\n",
    "def calc_desc_post_prob(test_data, train_data, label):\n",
    "    l = len(test_data)\n",
    "    posterior = 1\n",
    "    result = 1\n",
    "    for pos, val in enumerate(test_data):\n",
    "        if(pos < l - 1):\n",
    "            if(isinstance(val,float)):\n",
    "                #print(\"P : \" + str(val))\n",
    "                posterior = calculate_float_posterior(test_data, train_data, label, pos)\n",
    "            elif(isinstance(val,str)):\n",
    "                #print(\"Q : \" + str(val))\n",
    "                posterior = calculate_string_posterior(test_data, train_data, label, pos)\n",
    "            result = result * posterior\n",
    "    return result\n",
    "\n",
    "def calculate_float_posterior(test_data, train_data, label, position):\n",
    "    statistics = calculate_mean_variance(train_data, position)\n",
    "    hmap = {}\n",
    "    val = test_data[position]\n",
    "    #list = statistics[position]\n",
    "    #mean = list[0]\n",
    "    #variance = list[1]\n",
    "    stat_list = statistics.get(label)\n",
    "    mean = stat_list[0]\n",
    "    variance = stat_list[1]\n",
    "    temp = 1.0 / (math.sqrt((2 * math.pi * variance)))\n",
    "    numerator = (-(val - mean)**2) / (2 * variance)\n",
    "    exp = math.exp(numerator)\n",
    "    result = temp * exp\n",
    "    return result\n",
    "\n",
    "def calculate_string_posterior(test_data, train_data, label, position):\n",
    "    statistics = calculate_string_statistics(train_data, position)\n",
    "    value = statistics.get(label)\n",
    "    length = len(value)\n",
    "    attribute = test_data[position]\n",
    "    count = 0\n",
    "    for pos, val in enumerate(value):\n",
    "        if(attribute == val):\n",
    "            count = count + 1\n",
    "    result = count / float(length)\n",
    "    return result\n",
    "\n",
    "def calculate_string_statistics(train_data, position):\n",
    "    statistics = {}\n",
    "    for pos, val in enumerate(train_data):\n",
    "        label = val[-1]\n",
    "        attribute = val[position]\n",
    "        if label in statistics:\n",
    "            tmp = statistics.get(label)\n",
    "            tmp.append(attribute)\n",
    "            statistics[label] = tmp\n",
    "        else:\n",
    "            temp = []\n",
    "            temp.append(attribute)\n",
    "            statistics[label] = temp\n",
    "    return statistics\n",
    "\n",
    "def calculate_descriptor_prior_probability(test_data, train_data):\n",
    "    hmap = {}\n",
    "    descriptor_prior = 1\n",
    "    length = len(train_data)\n",
    "    l = len(test_data)\n",
    "    for pos, val in enumerate(test_data):\n",
    "        if(pos < l - 1):\n",
    "            for p, q in enumerate(train_data):\n",
    "                for i in range(len(q)):\n",
    "                    if(i < l - 1):\n",
    "                        if((i == pos) and (q[i] == val)):\n",
    "                            if i in hmap:\n",
    "                                hmap[i] = hmap[i] + 1\n",
    "                            else:\n",
    "                                hmap[i] = 1\n",
    "    for key in hmap.keys():\n",
    "        val = hmap.get(key)\n",
    "        descriptor_prior = (descriptor_prior / float(length)) * val\n",
    "    return descriptor_prior\n",
    "\n",
    "def calculate_statistics(test_data, predicted_labels):\n",
    "    length = len(test_data)\n",
    "    tn = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for i in range(length):\n",
    "        if(predicted_labels[i] == test_data[i][-1]):\n",
    "            if(predicted_labels[i] == 0):\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if(predicted_labels[i] == 0 and test_data[i][-1] == 1):\n",
    "                fn = fn + 1\n",
    "            elif(predicted_labels[i] == 1 and test_data[i][-1] == 0):\n",
    "                fp = fp + 1\n",
    "    try:\n",
    "        accuracy = 100.0 * ((tp + tn) / float(tn + tp + fn + fp))\n",
    "    except ZeroDivisionError:\n",
    "        accuracy = 100.0 * (tp + tn)\n",
    "    try:\n",
    "        precision = tp / float(tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = tp\n",
    "    try:\n",
    "        recall = tp / float(tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = tp\n",
    "    try:\n",
    "        f_measure = (2 * tp) / float((2 * tp) + fn + fp)\n",
    "    except ZeroDivisionError:\n",
    "        f_measure = (2 * tp)\n",
    "    return accuracy, precision, recall, f_measure\n",
    "\n",
    "    \n",
    "file_name = \"project3_dataset1.txt\"\n",
    "#file_name = \"project3_dataset2.txt\"\n",
    "\n",
    "k_fold_validation = 10\n",
    "\n",
    "# Load the corresponding dataset to fetch records.\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_measure = 0\n",
    "predicted_labels = []\n",
    "records = load_dataset(file_name)\n",
    "for i in range(k_fold_validation):\n",
    "    print(\"\\nIteration \" + str(i+1))\n",
    "    train_data, test_data = form_training_testing_data(records,k_fold_validation, i+1)\n",
    "    predicted_labels = []\n",
    "    class_prior_probablity = calculate_class_prior(train_data)\n",
    "    \n",
    "    for pos, val in enumerate(test_data):\n",
    "        class_zero_prob = calc_desc_post_prob(val, train_data, 0)\n",
    "        class_one_prob = calc_desc_post_prob(val, train_data, 1)\n",
    "        \n",
    "        descriptor_prior = calculate_descriptor_prior_probability(val, train_data)\n",
    "        \n",
    "        zero = class_zero_prob * float (class_prior_probablity.get(0))\n",
    "        one = class_one_prob * float (class_prior_probablity.get(1))\n",
    "        \n",
    "        class_zero_final_prob = zero / float (descriptor_prior)\n",
    "        class_one_final_prob = one / float (descriptor_prior)\n",
    "        \n",
    "        if(class_zero_final_prob > class_one_final_prob):\n",
    "            predicted_labels.append(0)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    acc, prec, rec, f = calculate_statistics(test_data, predicted_labels)\n",
    "    accuracy = accuracy + acc\n",
    "    precision = precision + prec\n",
    "    recall = recall + rec\n",
    "    f_measure = f_measure + f\n",
    "    print(\"*** Iteration \" + str(i+1) + \" Statistics *** \")\n",
    "    print(\"Accuracy : \" + str(acc))\n",
    "    print(\"Precision : \" + str(prec))\n",
    "    print(\"Recall : \" + str(rec))\n",
    "    print(\"F-1 Measure : \" + str(f))\n",
    "\n",
    "accuracy = accuracy / float (k_fold_validation)\n",
    "precision = precision / float (k_fold_validation)\n",
    "recall = recall / float (k_fold_validation)\n",
    "f_measure = f_measure / float (k_fold_validation)\n",
    "print(\"\\n\\n***** Naive Bayes Classification Statistics Obtained Using \" + str(k_fold_validation)+ \"-Fold Cross Validation ***** \")\n",
    "print(\"Accuracy : \" + str(accuracy))\n",
    "print(\"Precision : \" + str(precision))\n",
    "print(\"Recall : \" + str(recall))\n",
    "print(\"F-1 Measure : \" + str(f_measure))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
